#!/usr/bin/env python
#######################################################################
#  This file is part of JMdictDB. 
#  Copyright (c) 2010 Stuart McGraw 
# 
#  JMdictDB is free software; you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published 
#  by the Free Software Foundation; either version 2 of the License, 
#  or (at your option) any later version.
# 
#  JMdictDB is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
# 
#  You should have received a copy of the GNU General Public License
#  along with JMdictDB; if not, write to the Free Software Foundation,
#  51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA
#######################################################################

__version__ = ('$Revision$'[11:-2],
	       '$Date$'[7:-11])

# This program will process a file of wwwjdict submission data
# and turn it into a set of files, one per submission, that can
# be opened by cgi script jbedit.py to present an html Edit Entry
# page with the edit boxes initialized with the submission's
# data, ready for review and submission.

# FIXME: The files generated by this program contain entry
#  data based on database lookups done at the time this program
#  is run.  Those files are read by cgi script jbedit.py some
#  indeterminate later.  This presents two problems: 
#  1) The database used by jbedit.py might be a different
#     database than used by this program.  Make sure the -D
#     database used when running this program, is the same one
#     that will be used by ...\cgi\jbedit.py (specified indirectly
#     via the "&svc=" url parameter.)
#  2) The database might be the same but may have been reloaded
#     since this program was run, invalidating the entry numbers
#     used here and saved in the output and thus inadvertantly
#     but invalidly used later by jbedit.py.
#  It might by better to move the functions of create_entry() 
#  (where the database lookups are done) into the jbedit.cgi
#  script so that the lookups are done at the same time the
#  database submissions will be made.

import sys, re, collections, datetime, os.path, itertools, pdb
import jdb, jmcgi, fmtjel, edparse, serialize
from edparse import ParseError as eParseError

Input_encoding = 'utf-8'
Output_encoding = 'utf-8'

# FIXME: we import edparse's ParseError.  Can we use that instead
#  of defining our own? 

class ParseError (Exception):
    def __init__(self, msg, line=None, linenum=None):
	self.msg = msg; self.line=line; self.linenum=linenum
    def __str__(self):
	return self.msg
	  #+ (" in submission starting at line %d" % (self.linenum)) if self.linenum else ''\
	  #+ ("  at line '%s'." % (self.line)) if self.line else ''
	
def main (args, opts):
	cursor = jdb.dbOpen (opts.database, **jdb.dbopts(opts))
	process_file (cursor, args[0], opts.outdir, opts.prefix,
		      opts.verbose, opts.start, opts.count, opts.force)

def process_file (cursor, inpname, outdir, prefix='', verbose=False,
		  start_at=1, max_subs=0, overwrite=False):
	# cursor -- An open psycopg2 database cursor to a
	#	jmdictdb database.
	# impname -- Name of the input file to process. (str)
	# outdir -- Path to directory where output and log files
	#	will be written.
	# prefix -- Names of all editdata and log output files 
	#	will be prefixed with this string, if given.
	# verbose -- If false, only print a line to stdout for
	#	submissions that failed conversion and that did
	#	not produce an editdata file.  If true, a line
	#	for each submission sucessfully parsed is written
	#	as well.
	# start_at -- Number of the submission (numbering starts
	#	at 1) to start processing.  Submissions before that
	#	will be ignored.
	# max_subs -- Maximum number of submissions to process.
	#	If 0, there is no limit.
	# overwrite -- If true, output file will be (over-)written
	# 	if it already exists.  If false, the output file will
	#       not be overwritten, an error message generated, and
	#       this input file skipped. 

	in_f = open (inpname, "r")
	bad_f = open (os.path.join (outdir, prefix+"bad.log"), "a")
	good_f = open (os.path.join (outdir, prefix+"ok.log"), "a")
	startmsg = "# %s: processing %s" %\
		(datetime.datetime.now().ctime(), inpname)
	print >>bad_f, startmsg
	print >>good_f, startmsg
	subnum = count = badcnt = 0

	  # Process each submission in open file 'inp_f'.
	  # If there is a problem parsing a submission, it is
	  # appended to the 'bad_f' file and an appropriate
	  # error message generated.  Otherwise, it is reformated
	  # to JEL and written to a newly created. per-submission
	  # file in directory 'outdir', where a cgi script page 
	  # will later (independently of this program) read it
	  # and submit it under human supervision.
	  
	for r in incremental_scanner (in_f, Input_encoding):
	    lines, linenum = r
	    subnum += 1
	    if subnum < start_at: continue
	    count += 1
	    if max_subs and count > max_subs: break

	    out_fn = prefix + "%0.5d.dat" % subnum
	    try: 
		parsed = parse_submission (lines)
		entr = create_entr (cursor, parsed, subnum)
		entrdata = [entr, parsed.get('reference'),
				  parsed.get('comment'),
			    	  parsed.get('name'),
			          parsed.get('email')]
		#--- debug
		#print "submission %d" % subnum
		#print "ktxt:", entr.ktxt
		#print "rtxt:", entr.rtxt
		#print "stxt:", entr.stxt
		#---

		ovwt = write_data (entrdata, os.path.join (outdir, out_fn), overwrite)
		if ovwt and verbose:
		    print "Overwriting output file %s" % out_fn
	    except ParseError, excep:
		msg = "Failed on submission %d (line %d): %s" \
		       % (subnum, linenum, str(excep))
		write_bad (bad_f, lines, msg)
		badcnt += 1
		continue
	    write_good (good_f, lines, "Parsed submission %d (line %d), wrote to %s"\
					% (subnum, linenum, out_fn), verbose)
	print "%s total submissions processed, %d good, %d bad" % (count-1, count-badcnt-1, badcnt)
	in_f.close();  bad_f.close();  good_f.close()

def write_bad (bad_f, lines, msg):
	print msg
	msg = '# ' + msg.replace('\n', '\n# ')
	print >>bad_f, msg
	print >>bad_f, ('\n'.join (lines)).encode (Output_encoding)

def write_good (good_f, lines, msg, verbose):
	if verbose: print msg
	msg = '# ' + msg.replace('\n', '\n# ')
	print >>good_f, msg
	print >>good_f, ('\n'.join (lines)).encode (Output_encoding)

def write_data (editdata, fn, force=False):
	# editdata -- A list of 5 elements:
	#    1. An entry object that will be used to load the edit
	#	boxes in the edform.tal edit template.
	#    2, 3, 4, 5.  Texts for, respectively, "refs", "comments",
	#	"name", "email" edform.tal text boxes.
	# fn -- The name (with path) of the filename to write the
	#	editdata to.
	# force -- If true, output file will be overwritten if it
	#       exists.  If not true, an exception will be raised
	#       if the output file already exists.
	# 
	# Returns: True if the output file existed and was overwritten,
	#       or False otherwise.

	s = serialize.serialize (editdata)
	  # Dirty and unreliable test to avoid accidentily 
	  # over-writing an existing file...
	try: open (fn)
	except IOError: ovwt = False
	else:
	      #FIXME: this is not really a parse error, is it?
	    if force: ovwt = True
	    else: raise ParseError ("File exists, won't overwrite: %s" % fn)		 
	f = open (fn, "w")
	f.write (s)
	f.close()
	return ovwt

def write_msg (errmsg, lines, err_f=None):
	print errmsg
	if err_f: 
	    print >>err_f, ('# ' + errmsg.replace('\n', '\n# ')).encode (Output_encoding)
	    if lines: print >>err_f, ('\n'.join (lines)).encode (Output_encoding)

def incremental_scanner (f, encoding=None):
	  # This function is an iterator and thus may be used in a "for"
	  # statement where it will repeatedly supply 2-tuples consisting
	  # of:
	  #   * A list of the lines of the submission (including the
	  #     S-SUB and E-SUB lines. 
	  #   * The line number in 'f' of the first line of the 
	  #     submission.
	  # Lines in 'f' that begin with '#' (no whitespace preceeding
	  # it) are treated as comment lines and are are ignored other
	  # than being counted for maintaining the linenumber.  Lines
	  # are returned with trailing whitespace (including the EOL
	  # character) removed.  

	lines = [];  base_linenum = None
	for line_num, line in enumerate (f):
	    if encoding: line = line.decode (encoding)
	    if line_num == 0 and line.startswith(u'\uFEFF'):
		line = line[1:]			# Remove BOM.
	      # FIXME? it is possible the multi-line fields could 
	      #  contain lines starting with "#". 
	    if line.startswith ('#'): continue	# Skip comment lines.
	    line = line.rstrip()		# Remove trailing whitespace.
	    if base_linenum is None: base_linenum = line_num + 1
	    lines.append (line)
	    if line == "E-SUB": 
		yield lines, base_linenum 
		lines = []; base_linenum = line_num + 2
	if lines: yield lines, base_linenum

def parse_submission (lines):
	# Parse a list of lines extracted from a wwwjdic submission 
	# form data file.  The lines must constitute a single submission
	# starting with a "======= Date" or "S-SUB" line and ending with
	# a "E-SUB" line.  Errors encountered during parsing are signalled
	# by raising a ParseError exception.
	# If there are no errors, a dict is returned having keys 
	# corresponding to the fields of the form data, with sequenced
	# fields like "english1", "english2", ... coalesced into a single
	# key, "english", with a value is a list of the field values.

	collect = collections.defaultdict (list)
	known_keywds = 'origentry headw kana pos misc english crossref reference '\
			'comment entlangnam name email subtype sendNotJS date'.split()

	  # Following fields have values that can span multiple lines.
	multi_line = 'reference comment'.split()

	  # Following fields may occur more than once, e.g. headw1, headw2,...
	multi_field = 'headw kana pos misc english crossref   '.split()

	  # NOTE: multi-line and multi-field are mutually exclusive; don't
	  #  list the same field in both.

	n = 0;  ln = lines[n]
	if ln.startswith ('======= Date: '):
	    try: date = datetime.datetime.strptime (ln[14:], '%a %b %d %H:%M:%S %Y')
	    except ValueError: 
		raise ParseError ("Bad date", ln)
	      # Don't save the datetime object 'date' because we are prepared
	      # to handle only strings in 'collect' below (i.e. we call join()).
	    collect['date'].append (ln[14:])
	    n += 1;  ln = lines[n]
	if ln != 'S-SUB': 
	    raise ParseError ("Missing S-SUB", ln)
	n += 1;  got_esub = False;  kw = None
	for lnnum, ln in enumerate (lines[n:]):
	    if ln == ' (0)': continue
	    if got_esub:
	        raise ParseError ("Lines following E-SUB", ln)
	    if ln == "E-SUB": 
		got_esub = True; break
	    mo = re.match (r'\(([a-zA-Z]+)([0-9]+)?\)\t(.*)', ln)
	    if mo: 
		maybe_kw, cntr, val = mo.groups()
		  #FIXME? we ignore 'cntr'.  Should we check it?  use it?
		if maybe_kw in known_keywds:
		    kw = maybe_kw
		    collect[kw].append (val) 
		else: mo = None
	    if not mo:
		  # 'kw' here is from previous line(s) -- the last
		  # one that was validated in 'known_keywds'.  If 
		  # None, then it was never set above which means 
		  # we got a continuation line with no preceeding
		  # keyword line.
		if not kw:
		    raise ParseError ("Missing expected keyword line", ln)
		if kw not in multi_line:
		    raise ParseError ("Got multiple lines for '%s' keyword" % kw, ln)
		collect[kw].append (ln)
	    
	if not got_esub:
	    raise ParseError ("Missing E-SUB line")

	  # Turn 'collect' back into an ordinary dict so we can attempt
	  # to access keys without magically instantiating them (as a
	  # defaultdict does.) 
	collect = dict (collect)

	for kw in collect.keys():
	    if kw not in multi_field:
		  # All items in 'collect' were created as lists.
		  # Except for those that are intended to have multiple
		  # items (listed in multi_field), we convert the lists
		  # of lines back to a single line.
		collect[kw] = '\n'.join (collect[kw])
	if 'name'  in collect and collect['name']  == 'Name':          del collect['name']
	if 'email' in collect and collect['email'] == 'Email address': del collect['email']
	  # Sanity check to make sure we didn't accidently misplace something...
	for kw in collect.keys(): assert kw in known_keywds
	return collect

def create_entr (cursor, parsed, subnum):
	# From the dictionary of wwwjdict submission values in 
	# 'parsed' we create the same kind of data that cgi/edform.py
	# creates internally to send to the edform.tal template: an 
	# Entr object with some attached extra data.  This object is
	# returned to caller (who will serialize it and write it to
	# a file).

	if 'subtype' not in parsed or parsed['subtype'] not in ('new', 'amend'):
	    raise ParseError ("Missing or bad 'subtype' field")

	if parsed['subtype'] == 'new':
	    entr = jdb.Entr()
	    entr.src = jdb.KW.SRC['jmdict'].id
	else:	# == 'amend'
	    if 'origentry' not in parsed:
		raise ParseError ("subtype 'amend' but no 'origentry' field")
	    origentry = parsed['origentry']
	    mo = re.search (r'/ \(([0-9]{7})\)', origentry)
	    if not mo:  
		raise ParseError ("Can't find seq num in 'origentry' value", origentry)
	    seqnum = mo.group(1)
	    errs = []
	      # FIXME: following assumes seqnum is an entry in jmdict.
	    entrs = jmcgi.get_entrs (cursor, None, [seqnum], errs,
				     active=True, corpus='jmdict')
	    if errs: print "submission %d: %s" % '\n'.join (errs)
	    if entrs: entr = entrs[0]
	    else: raise ParseError ("Unable to get entry seq# %s from database" % seqnum)

	kanj = [];  rdng = []; gloss = []
	for x in parsed.get ('headw', []):
	    if jdb.jstr_reb (x): rdng.append (x)
	    else: kanj.append (x)
	rdng.extend (parsed.get ('kana', []))
	ktxt = ';'.join (kanj)
	rtxt = ';'.join (rdng)
	stxt = ' / '.join (parsed.get ('english', []))
	pos = ','.join (parsed.get ('pos', []))
	misc = ','.join (parsed.get ('misc', []))
	xref = ','.join (parsed.get ('crossref', []))
	  #FIXME: Note that including pos, xref. et.al. can break
	  # a sense parse that would otherwise be ok.  Maybe if the
	  # parse fails, we should try again without this stuff, 
	  # and if that works, append this stuff as "unparsable"-
	  # tagged extra text.
	  # However, senses other than the first may have this
	  # information embedded in the text and it seems a bit
	  # much to try pulling it out... 
	stxt = (('('+pos+')') if pos else '') \
		+ (('(See '+xref+')') if xref else '') \
		+ (('('+misc+')') if misc else '') \
		+ (' ' if pos or misc or xref else '') + stxt 

	  #FIXME:  What do about 'date', 'entlangnam' fields? 
	  # I don't think we care about 'sendNotJS'.

	ktxt, rtxt, stxt = reformat (ktxt, rtxt, stxt, entr, subnum)
	entr.ktxt, entr.rtxt, entr.stxt = ktxt, rtxt, stxt
	return entr

def reformat (ktxt, rtxt, stxt, entr, subnum):
	# Given edict2-formatted kanji, reading, and sense
	# strings, try to convert them into jmdictdb objects, 
	# and then format them back to JEL-formatted strings
	# which are returned.  If unable to parse an input
	# string, return the unparsed string prefixed with
        # "!unparsed!" instead of the JEL-formatted string.
        # If matching kanji or reading items exist on 'entr'
        # have and kinf, rinf, freq, or restrs, those items
        # are added to the JEL-formated string.

	failed = False;  kanjs = rdngs = senss = None;  fmap = {}

	  # Assume the worst and overwrite the following if  
	  # things work ok...
	jktxt = "!unparsed!\n" + ktxt
	jrtxt = "!unparsed!\n" + rtxt
	jstxt = "!unparsed!\n" + stxt

	try: 
	    kanjs = edparse.parse_krpart (ktxt, fmap) 
	except eParseError, excep: 
	    try: print "submission %d: reformat kanj failed: %s" % (subnum, unicode(excep))
	    except UnicodeError: "submission %d: reformat kanj failed: (unprintable exception)" % subnum

	if kanjs is not None:    # kanjs is None if kanji parse failed in
	    try:                 #  which case we can't parse readings or senses.
		rdngs = edparse.parse_krpart (rtxt, fmap, kanjs)
	    except eParseError, excep: 
		try: print "submission %d: reformat rdng failed: %s" % (subnum, unicode(excep))
		except UnicodeError: "submission %d: reformat rdng failed: (unprintable exception)" % subnum

        if rdngs is not None:    # rdngs is None if reading parse failed in 
	    if entr:             #  which case we can't parse senses.
		  # The wwwjdic submission data does not apparently
		  # include tags from the orignal entry so we copy 
		  # them here. 
		copy_tags (entr._rdng, entr._kanj, rdngs, kanjs)
	    e = jdb.Entr(_rdng=rdngs, _kanj=kanjs)
	    try: 
	        edparse.parse_spart (stxt, e, fmap) 
	        senss = e._sens
	        jktxt = fmtjel.kanjs (kanjs)
                jrtxt = fmtjel.rdngs (rdngs, kanjs)
	        jstxt = fmtjel.senss (senss, kanjs, rdngs)
	    except eParseError, excep:
		try: print "submission %d: reformat sens failed: %s" % (subnum, unicode(excep))
		except UnicodeError: "submission %d: reformat sens failed: (unprintable exception)" % subnum

	return jktxt, jrtxt, jstxt

def copy_tags (rdngs, kanjs, new_rdngs, new_kanjs):
	# It appears that the wwwjdic forms do not send any info
	# about the tags (kinf, rinf, or freq) or kr restrictions 
        # on the kana or kanji of an amended entry.  This function
        # will attempt to restore the tags that are on the original
        # entry to the edit entry to save the reviewer the effort of
        # manually re-adding them.
	#
	# CAUTION: this function is not intended for general-purpose
	# use...see comments below.

	  # Build a lookup dict for reading text -> Rng obj for
	  #  only Rdng objects that have Freq or Rinf tags.
	rmap = dict(((r.txt, r) for r in rdngs if r._freq or r._inf))

	  # Same for Kanj objects.
	kmap = dict(((k.txt, k) for k in kanjs if k._freq or k._inf))

	  # Build a lookup set for kanji,reading text pairs ->
	  #  Kanj, Rdng object pairs for only pairs that have
	  #  a common Restr object on their ._restr lists.
	krset = set(((k.txt, r.txt) 
		  for k, r in itertools.product (kanjs, rdngs)
		  if has_restr (k, r)))

	  # "Copy" the Freq and [KR]inf references from the 
	  # old entry Rdngs and Kanj to the new ones.  Note 
	  # that we do not copy the Freq or [KR]inf objects
	  # them selfselves but only the references to them.  
	  # Thus the objects are shared between the old and 
	  # new entries.  We get away with this because this
	  # function is not intended foe general-purpose use
	  # and we know that we are going to throw away both
	  # objects after they have been used to generate a
	  # textual representation.  We copy to the new Rdng
	  # or Kanj that has the same text as the old one so
	  # a change in position will not prevent the copy.
	  # Note that if there are already tag on the object,
	  # they will remain.  We do not check for duplicates.

	for r in new_rdngs:
	    if r.txt in rmap:
		r._freq.extend (rmap[r.txt]._freq)
		r._inf.extend (rmap[r.txt]._inf)
	for k in new_kanjs:
	    if k.txt in kmap: 
		k._freq.extend (kmap[k.txt]._freq)
		k._inf.extend (kmap[k.txt]._inf)

	  # To copy the Restr object, the new object must have
	  # both the same reading and kanji that were restricted 
	  # in the old entry.  'krmap' lists those pairs (by
	  # text) for the old entr.  itertools.product() will 
	  # give all combinations or Rdng and Kanj for the new
	  # object.  If the text pair exists in 'krmap', and
	  # if there is not already a restriction, then create 
	  # a new one.  Contrary to the caution above, this
	  # part of the code *does* create an independent copy,
	  # and avoids duplication.

	for k, r in itertools.product (new_kanjs, new_rdngs):
	    if (k.txt, r.txt) in krset: 
		if not has_restr (k, r): 
		    x = jdb.Restr()
		    k._restr.append (x)
		    r._restr.append (x)
		
def has_restr (k, r):
	# If Kanj object k and Rdng object r are linked via
	# a Restr object, return a reference to that object.
	# Otherwise return None.
	# FIXME: this probably belongs in jdb.

	if not k._restr or not r._restr: return None
	for kx in k._restr:
	    for rx in r._restr:
		if kx is rx: return kx
	    	

from optparse import OptionParser

def parse_cmdline ():
	u = \
"""\n\t%prog [options] input-file

  This program reads an input file containing raw wwwjdic submission 
  form data, and creates a number of output files, one for each 
  submission in the input file, that can be subesequently read by
  cgi script jbedit.py to present a jmdict edit form, initialized
  with the submission data which can be reviewed and submitted as 
  a jmdict database entry.

  The output files are named "nnnnn.dat" where "nnnnn" is a five-
  digit number that is the ordinal position of the submission in
  the input file.  The filename may prefixed with an arbitrary text
  string by using the option "--prefix".  The directory these files
  are created in is given by --outdir which defaults to the current
  directory.

  Also produced (in --outdir, and prefixed with --prefix) are two 
  log files, ok.log and bad.log.  [TBD... finish this description]

  *** WARNING ***  If the jmdictdb database is reloaded from xml
  after this program has been run but before jbedit.py is used
  to review the submissions, this program's output files will be
  invalidated and jbedit.py will produce invalid edits if it uses
  them.  

Arguments:  Name of input file containing raw submission data."""

	v = sys.argv[0][max (0,sys.argv[0].rfind('\\')+1):] \
	        + " Rev %s (%s)" % __version__
	p = OptionParser (usage=u, version=v)

	p.add_option ("-o", "--outdir", default='.',
            help="Path to directory in which to create output files "
		"including the \"bad\" and \"ok\" log files.  Default "
		"is the current directory.")
	p.add_option ("-p", "--prefix", default='',
            help="Text that will be used to prefix the files created in OUTDIR.")
	p.add_option ("-s", "--start", type="int", default=1,
            help="Skip submissions at beginning of file and start processing "
		"at submission START.  Default is 1 (skip none).")
	p.add_option ("-c", "--count", type="int", default=0,
            help="Process at most COUNT submissions.  Default is 0 (no limit).")
	p.add_option ("-f", "--force", default=False, action="store_true",
            help="Force the overwriting of the output file if it already exists.  "
	        "If not given, jbsubs will refuse to overwrite the file, generate "
		"an error message to that effect and go on to the next submission "
                "in the input file.")
	p.add_option ("-v", "--verbose", default=False, action="store_true",
            help="Print message for each sucessfully parsed submission.")

	p.add_option ("-D", "--database", default="jmdict",
            help="Name of the database to load.  Default is \"jmdict\".")
	p.add_option ("-H", "--host",
            help="Name host machine database resides on.  Default is localhost.")
	p.add_option ("-U", "--user",
            help="Connect to database with this username.  Not needed if you "
		"have set up a .pgpass file which is recommended.")
	p.add_option ("-P", "--password",
            help="Connect to database with this password.  Not needed if you "
		"have set up a .pgpass file which is recommended.")

	opts, args = p.parse_args ()
	if len(args) < 1: p.error ("Need argument")
	if len(args) > 1: p.error ("Expected only one argument")
	return args, opts

if __name__ == '__main__': 
	args, opts = parse_cmdline ()
	main (args, opts)


